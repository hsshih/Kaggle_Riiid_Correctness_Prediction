{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-06T21:21:54.013376Z",
     "iopub.status.busy": "2021-01-06T21:21:54.012534Z",
     "iopub.status.idle": "2021-01-06T21:21:54.016671Z",
     "shell.execute_reply": "2021-01-06T21:21:54.016062Z"
    },
    "papermill": {
     "duration": 0.025905,
     "end_time": "2021-01-06T21:21:54.016763",
     "exception": false,
     "start_time": "2021-01-06T21:21:53.990858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This Python 3 environment comes with many helpful analytics libraries installed\n",
    "## It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "## For example, here's several helpful packages to load\n",
    "\n",
    "#import numpy as np # linear algebra\n",
    "#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "## Input data files are available in the read-only \"../input/\" directory\n",
    "## For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "#import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "## You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "## You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01543,
     "end_time": "2021-01-06T21:21:54.048257",
     "exception": false,
     "start_time": "2021-01-06T21:21:54.032827",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A Self_Attention model for Knowledge Tracing (Pandey & Karypis 2019)\n",
    "https://arxiv.org/pdf/1907.06837.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:21:54.086644Z",
     "iopub.status.busy": "2021-01-06T21:21:54.085883Z",
     "iopub.status.idle": "2021-01-06T21:21:56.646255Z",
     "shell.execute_reply": "2021-01-06T21:21:56.644602Z"
    },
    "papermill": {
     "duration": 2.582403,
     "end_time": "2021-01-06T21:21:56.646387",
     "exception": false,
     "start_time": "2021-01-06T21:21:54.063984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:21:56.687464Z",
     "iopub.status.busy": "2021-01-06T21:21:56.686750Z",
     "iopub.status.idle": "2021-01-06T21:23:54.852171Z",
     "shell.execute_reply": "2021-01-06T21:23:54.851641Z"
    },
    "papermill": {
     "duration": 118.190053,
     "end_time": "2021-01-06T21:23:54.852276",
     "exception": false,
     "start_time": "2021-01-06T21:21:56.662223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 4.31 s, total: 1min 14s\n",
      "Wall time: 1min 58s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  user_id  content_id  content_type_id  answered_correctly\n",
       "0          0      115        5692                0                   1\n",
       "1      56943      115        5716                0                   1\n",
       "2     118363      115         128                0                   1\n",
       "3     131167      115        7860                0                   1\n",
       "4     137965      115        7922                0                   1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dtype = {'timestamp': 'int64', 'user_id': 'int32' ,'content_id': 'int16','content_type_id': 'int8','answered_correctly':'int8'}\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv', usecols=[1,2,3,4,7], dtype=dtype)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:23:54.891136Z",
     "iopub.status.busy": "2021-01-06T21:23:54.890355Z",
     "iopub.status.idle": "2021-01-06T21:24:22.125605Z",
     "shell.execute_reply": "2021-01-06T21:24:22.125001Z"
    },
    "papermill": {
     "duration": 27.256893,
     "end_time": "2021-01-06T21:24:22.125711",
     "exception": false,
     "start_time": "2021-01-06T21:23:54.868818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## content_type_id: (int8) \n",
    "## 0 if the event was a question being posed to the user, \n",
    "## 1 if the event was the user watching a lecture.\n",
    "## Only take the rows with content_type_id = 0\n",
    "train_df = train_df[train_df.content_type_id == False]\n",
    "\n",
    "## Arrange by timestamp\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:24:22.168971Z",
     "iopub.status.busy": "2021-01-06T21:24:22.167506Z",
     "iopub.status.idle": "2021-01-06T21:24:23.447566Z",
     "shell.execute_reply": "2021-01-06T21:24:23.448351Z"
    },
    "papermill": {
     "duration": 1.303847,
     "end_time": "2021-01-06T21:24:23.448516",
     "exception": false,
     "start_time": "2021-01-06T21:24:22.144669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of skills 13523\n"
     ]
    }
   ],
   "source": [
    "# n_skill = number of unique questions\n",
    "skills = train_df[\"content_id\"].unique()\n",
    "n_skill = len(skills)\n",
    "print(\"number of skills\", len(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:24:23.507173Z",
     "iopub.status.busy": "2021-01-06T21:24:23.506276Z",
     "iopub.status.idle": "2021-01-06T21:25:06.002244Z",
     "shell.execute_reply": "2021-01-06T21:25:06.000749Z"
    },
    "papermill": {
     "duration": 42.528569,
     "end_time": "2021-01-06T21:25:06.002415",
     "exception": false,
     "start_time": "2021-01-06T21:24:23.473846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Group by user id\n",
    "group = train_df[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply(lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values))\n",
    "\n",
    "#del train_df\n",
    "#group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:25:06.061639Z",
     "iopub.status.busy": "2021-01-06T21:25:06.057065Z",
     "iopub.status.idle": "2021-01-06T21:25:06.064607Z",
     "shell.execute_reply": "2021-01-06T21:25:06.063998Z"
    },
    "papermill": {
     "duration": 0.041397,
     "end_time": "2021-01-06T21:25:06.064716",
     "exception": false,
     "start_time": "2021-01-06T21:25:06.023319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAKTDataset(Dataset):\n",
    "    def __init__(self, group, n_skill, max_seq=100):\n",
    "        super(SAKTDataset, self).__init__()\n",
    "        ## max_seq = the maximum length the model can handel\n",
    "        ## n_skill = number of questions/exercise\n",
    "        self.max_seq = max_seq\n",
    "        self.n_skill = n_skill\n",
    "        self.samples = group\n",
    "        \n",
    "        #self.user_ids = [x for x in group.index]\n",
    "        self.user_ids = []\n",
    "        for user_id in group.index:\n",
    "            q, qa = group[user_id]\n",
    "            ## skip users that answer less than 10 questions\n",
    "            if len(q) < 10:\n",
    "                continue   ## continue returns the control to the beginning of the loop\n",
    "            self.user_ids.append(user_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user_ids[index]\n",
    "        ## q_ = questions user answered\n",
    "        ## qa_ = user answer to question\n",
    "        q_, qa_ = self.samples[user_id]\n",
    "        ## seq_len = number of questions user answered\n",
    "        seq_len = len(q_)\n",
    "        \n",
    "        ## padded sequences same length as max_seq\n",
    "        q = np.zeros(self.max_seq, dtype=int)\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "        \n",
    "        ## if length of sequence longer than max_seq, only take the most recently answered questions equal to max_seq\n",
    "        ## otherwise keep all questions and answers, pad with zeroes to make sequence length = max_seq\n",
    "        if seq_len >= self.max_seq:\n",
    "            q[:] = q_[-self.max_seq:]\n",
    "            qa[:] = qa_[-self.max_seq:]\n",
    "        else:\n",
    "            q[-seq_len:] = q_\n",
    "            qa[-seq_len:] = qa_\n",
    "        \n",
    "        ## skip first question since there is no previous question to use (??)\n",
    "        target_id = q[1:]\n",
    "        label = qa[1:]\n",
    "\n",
    "        ## From paper: \n",
    "        ## The interaction tuple xt = (et, rt) is presented to the model as a number\n",
    "        ## yt = et + rt × E, where E is the total number of questions/exercises.\n",
    "        x = np.zeros(self.max_seq-1, dtype=int)\n",
    "        x = q[:-1].copy()\n",
    "        x += (qa[:-1] == 1) * self.n_skill\n",
    "\n",
    "        return x, target_id, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:25:06.115418Z",
     "iopub.status.busy": "2021-01-06T21:25:06.114541Z",
     "iopub.status.idle": "2021-01-06T21:25:10.288799Z",
     "shell.execute_reply": "2021-01-06T21:25:10.288076Z"
    },
    "papermill": {
     "duration": 4.203569,
     "end_time": "2021-01-06T21:25:10.288911",
     "exception": false,
     "start_time": "2021-01-06T21:25:06.085342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Split 80/20 into train and val\n",
    "train, val = train_test_split(group, test_size=0.2)\n",
    "\n",
    "train_dataset = SAKTDataset(train, n_skill)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2048, shuffle=True, num_workers=8)\n",
    "del train\n",
    "\n",
    "val_dataset = SAKTDataset(val, n_skill)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2048, shuffle=True, num_workers=8)\n",
    "del val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017577,
     "end_time": "2021-01-06T21:25:10.324520",
     "exception": false,
     "start_time": "2021-01-06T21:25:10.306943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:25:10.389507Z",
     "iopub.status.busy": "2021-01-06T21:25:10.387649Z",
     "iopub.status.idle": "2021-01-06T21:25:10.390237Z",
     "shell.execute_reply": "2021-01-06T21:25:10.390704Z"
    },
    "papermill": {
     "duration": 0.048213,
     "end_time": "2021-01-06T21:25:10.390815",
     "exception": false,
     "start_time": "2021-01-06T21:25:10.342602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    ## Feed-forward neural net\n",
    "    ## S = Multihead(Mˆ, Eˆ)\n",
    "    ## Mˆ = embedded interaction input matrix,  Eˆ = embedded exercise matrix \n",
    "    ## F = FFN(S) = ReLU(SW(1) + b(1))W(2) + b(2)\n",
    "    def __init__(self, state_size=200):\n",
    "        super(FFN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        \n",
    "        ## nn.Linear applies a linear transformation to the incoming data y=xA+b\n",
    "        ## input state_size, output state_size\n",
    "        self.lr1 = nn.Linear(state_size, state_size)\n",
    "        ## nn.relu applies the rectified linear unit function element-wise:\n",
    "        ## ReLU(x) = (x)^+ = \\max(0, x)ReLU(x)=(x)+=max(0,x)\n",
    "        self.relu = nn.ReLU()\n",
    "        ## Second linear transformation to incorporate non-linearity in model\n",
    "        self.lr2 = nn.Linear(state_size, state_size)\n",
    "        \n",
    "        ## dropout for regularization\n",
    "        ## randomly zeroes some of the elements of the input tensor with probability p = 0.2\n",
    "        self.dropout = nn.Dropout(0.2) \n",
    "    \n",
    "    def forward(self, x): \n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr2(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def future_mask(seq_length):\n",
    "    ## np.triu returns the upper triangle of the matrix\n",
    "    ## with the elements below the k-th diagonal zeroed\n",
    "    ## only use the previous questions to predict answer to current question, ignore future questions\n",
    "    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n",
    "    return torch.from_numpy(future_mask)\n",
    "\n",
    "\n",
    "class SAKTModel(nn.Module):\n",
    "    def __init__(self, n_skill, max_seq=100, embed_dim=128):\n",
    "        super(SAKTModel, self).__init__()\n",
    "        self.n_skill = n_skill\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        ## The interaction tuple xt = (et, rt) is presented to the model as a number\n",
    "        ## yt = et + rt × E, where E is the total number of exercises.\n",
    "        ## Thus, the total values that an element in the interaction sequence can take is 2E (rt = 1 or 0),\n",
    "        self.embedding = nn.Embedding(2*n_skill+1, embed_dim)\n",
    "        ## while elements in the exercise sequence can take E possible values\n",
    "        self.e_embedding = nn.Embedding(n_skill+1, embed_dim)\n",
    "        ## Position Encoding is the layer in the self-attention neural network which is used for encoding the\n",
    "        ## position so that like convolution network and recurrent neural network, we can encode the order of the sequence.\n",
    "        self.pos_embedding = nn.Embedding(max_seq-1, embed_dim)\n",
    "        ## embed_dim = latent dimensions / dimension of embedding vector\n",
    "        \n",
    "        ## Multihead self-attention, with 8 attention heads\n",
    "        self.multi_att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=8, dropout=0.2)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer_normal = nn.LayerNorm(embed_dim) \n",
    "\n",
    "        self.ffn = FFN(embed_dim)\n",
    "        self.pred = nn.Linear(embed_dim, 1)\n",
    "    \n",
    "    def forward(self, x, question_ids):\n",
    "        device = x.device        \n",
    "        x = self.embedding(x)\n",
    "        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n",
    "\n",
    "        pos_x = self.pos_embedding(pos_id)\n",
    "        ##  The ith row of position embedding matrix, Pi is then added to \n",
    "        ##the interaction embedding vector of the ith element of the interaction sequence.\n",
    "        x = x + pos_x\n",
    "\n",
    "        e = self.e_embedding(question_ids)\n",
    "\n",
    "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        e = e.permute(1, 0, 2)\n",
    "        att_mask = future_mask(x.size(0)).to(device)\n",
    "        ## Self-attention layer\n",
    "        ## Query from exercise embedding e\n",
    "        ## Key and Value from embedding of interaction sequence x = yt = et + rt × E\n",
    "        att_output, att_weight = self.multi_att(e, x, x, attn_mask=att_mask)\n",
    "        ## Normalization and residual layer\n",
    "        att_output = self.layer_normal(att_output + e)\n",
    "        att_output = att_output.permute(1, 0, 2) # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
    "\n",
    "        ## Feed-forward layers\n",
    "        x = self.ffn(att_output)\n",
    "        ## Normalization and residual layer\n",
    "        x = self.layer_normal(x + att_output)\n",
    "        x = self.pred(x)\n",
    "\n",
    "        return x.squeeze(-1), att_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:25:10.801282Z",
     "iopub.status.busy": "2021-01-06T21:25:10.800545Z",
     "iopub.status.idle": "2021-01-06T21:25:15.236364Z",
     "shell.execute_reply": "2021-01-06T21:25:15.235785Z"
    },
    "papermill": {
     "duration": 4.827732,
     "end_time": "2021-01-06T21:25:15.236477",
     "exception": false,
     "start_time": "2021-01-06T21:25:10.408745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SAKTModel(n_skill, embed_dim=128)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.99, weight_decay=0.005)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:25:15.289958Z",
     "iopub.status.busy": "2021-01-06T21:25:15.287819Z",
     "iopub.status.idle": "2021-01-06T21:25:15.292215Z",
     "shell.execute_reply": "2021-01-06T21:25:15.292650Z"
    },
    "papermill": {
     "duration": 0.036332,
     "end_time": "2021-01-06T21:25:15.292767",
     "exception": false,
     "start_time": "2021-01-06T21:25:15.256435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_iterator, optim, criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(train_iterator)\n",
    "    for item in tbar:\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "        label = item[2].to(device).float()\n",
    "        ## ignore output if target_id (content_id in original data frame) = 0\n",
    "        target_mask = (target_id != 0)\n",
    "        \n",
    "        ## In PyTorch, we need to set the gradients to zero before starting to do backpropragation \n",
    "        ## because PyTorch accumulates the gradients on subsequent backward passes.\n",
    "        optim.zero_grad()\n",
    "        output, atten_weight = model(x, target_id)\n",
    "        \n",
    "        output = torch.masked_select(output, target_mask)\n",
    "        label = torch.masked_select(label, target_mask)\n",
    "        \n",
    "        loss = criterion(output, label)\n",
    "        ## loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. \n",
    "        ## These are accumulated into x.grad for every parameter x.\n",
    "        loss.backward()\n",
    "        ## optimizer.step updates the value of x using the gradient x.grad\n",
    "        optim.step()\n",
    "        train_loss.append(loss.item())\n",
    "        ## apply sigmoid to output prediction\n",
    "        ## Sigmoid(z) = 1/(1 + e^−z)\n",
    "        ## If sigmoid of output >= 0.5, user is predicted to answer the question correctly for comparison with label\n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.average(train_loss)\n",
    "\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-01-06T21:25:15.333719Z",
     "iopub.status.busy": "2021-01-06T21:25:15.333123Z",
     "iopub.status.idle": "2021-01-06T21:25:15.336528Z",
     "shell.execute_reply": "2021-01-06T21:25:15.337188Z"
    },
    "papermill": {
     "duration": 0.026052,
     "end_time": "2021-01-06T21:25:15.337334",
     "exception": false,
     "start_time": "2021-01-06T21:25:15.311282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_sigmoid = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "#test_sigmoid = torch.FloatTensor(test_sigmoid)\n",
    "#print(torch.sigmoid(test_sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:25:15.390983Z",
     "iopub.status.busy": "2021-01-06T21:25:15.384707Z",
     "iopub.status.idle": "2021-01-06T21:25:15.393155Z",
     "shell.execute_reply": "2021-01-06T21:25:15.393655Z"
    },
    "papermill": {
     "duration": 0.03754,
     "end_time": "2021-01-06T21:25:15.393757",
     "exception": false,
     "start_time": "2021-01-06T21:25:15.356217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_epoch(model, val_iterator, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(val_iterator)\n",
    "    for item in tbar:\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "        label = item[2].to(device).float()\n",
    "        target_mask = (target_id != 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, atten_weight = model(x, target_id)\n",
    "        \n",
    "        output = torch.masked_select(output, target_mask)\n",
    "        label = torch.masked_select(label, target_mask)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.average(train_loss)\n",
    "\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-01-06T21:25:15.473453Z",
     "iopub.status.busy": "2021-01-06T21:25:15.472731Z",
     "iopub.status.idle": "2021-01-06T21:41:05.121394Z",
     "shell.execute_reply": "2021-01-06T21:41:05.122102Z"
    },
    "papermill": {
     "duration": 949.709981,
     "end_time": "2021-01-06T21:41:05.122262",
     "exception": false,
     "start_time": "2021-01-06T21:25:15.412281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5948: 100%|██████████| 153/153 [00:30<00:00,  5.01it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0 train_loss - 0.63 acc - 0.653 auc - 0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5931: 100%|██████████| 39/39 [00:07<00:00,  5.11it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0 val_loss - 0.59 acc - 0.685 auc - 0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5801: 100%|██████████| 153/153 [00:29<00:00,  5.23it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 1 train_loss - 0.58 acc - 0.691 auc - 0.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5816: 100%|██████████| 39/39 [00:05<00:00,  6.84it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 1 val_loss - 0.58 acc - 0.696 auc - 0.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5715: 100%|██████████| 153/153 [00:29<00:00,  5.25it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 2 train_loss - 0.58 acc - 0.697 auc - 0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5746: 100%|██████████| 39/39 [00:05<00:00,  6.66it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 2 val_loss - 0.57 acc - 0.698 auc - 0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5741: 100%|██████████| 153/153 [00:29<00:00,  5.24it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 3 train_loss - 0.57 acc - 0.699 auc - 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5771: 100%|██████████| 39/39 [00:05<00:00,  6.79it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 3 val_loss - 0.57 acc - 0.700 auc - 0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5675: 100%|██████████| 153/153 [00:30<00:00,  5.09it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 4 train_loss - 0.57 acc - 0.700 auc - 0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5820: 100%|██████████| 39/39 [00:06<00:00,  6.48it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 4 val_loss - 0.57 acc - 0.700 auc - 0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5701: 100%|██████████| 153/153 [00:30<00:00,  5.02it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 5 train_loss - 0.57 acc - 0.701 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5790: 100%|██████████| 39/39 [00:06<00:00,  6.29it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 5 val_loss - 0.57 acc - 0.701 auc - 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5698: 100%|██████████| 153/153 [00:30<00:00,  5.06it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 6 train_loss - 0.57 acc - 0.702 auc - 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5686: 100%|██████████| 39/39 [00:06<00:00,  6.11it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 6 val_loss - 0.57 acc - 0.701 auc - 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5723: 100%|██████████| 153/153 [00:30<00:00,  4.97it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 7 train_loss - 0.57 acc - 0.702 auc - 0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5780: 100%|██████████| 39/39 [00:06<00:00,  6.13it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 7 val_loss - 0.57 acc - 0.701 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5681: 100%|██████████| 153/153 [00:29<00:00,  5.20it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 8 train_loss - 0.57 acc - 0.703 auc - 0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5717: 100%|██████████| 39/39 [00:06<00:00,  5.58it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 8 val_loss - 0.57 acc - 0.702 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5639: 100%|██████████| 153/153 [00:29<00:00,  5.11it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 9 train_loss - 0.57 acc - 0.703 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5636: 100%|██████████| 39/39 [00:06<00:00,  6.22it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 9 val_loss - 0.57 acc - 0.702 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5676: 100%|██████████| 153/153 [00:29<00:00,  5.21it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 10 train_loss - 0.57 acc - 0.704 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5725: 100%|██████████| 39/39 [00:06<00:00,  6.09it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 10 val_loss - 0.57 acc - 0.702 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5647: 100%|██████████| 153/153 [00:29<00:00,  5.16it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 11 train_loss - 0.57 acc - 0.704 auc - 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5723: 100%|██████████| 39/39 [00:06<00:00,  5.87it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 11 val_loss - 0.57 acc - 0.702 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5616: 100%|██████████| 153/153 [00:30<00:00,  5.00it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 12 train_loss - 0.57 acc - 0.704 auc - 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5740: 100%|██████████| 39/39 [00:06<00:00,  5.99it/s]\n",
      "  0%|          | 0/153 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 12 val_loss - 0.57 acc - 0.702 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5697: 100%|██████████| 153/153 [00:30<00:00,  5.03it/s]\n",
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 13 train_loss - 0.57 acc - 0.705 auc - 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.5729: 100%|██████████| 39/39 [00:06<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 13 val_loss - 0.57 acc - 0.701 auc - 0.759\n",
      "early stop epoch  13\n",
      "CPU times: user 12min 58s, sys: 49.9 s, total: 13min 48s\n",
      "Wall time: 15min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 20\n",
    "\n",
    "over_fit = 0\n",
    "last_auc = 0\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc, train_auc = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
    "    print(\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, train_loss, train_acc, train_auc))\n",
    "    \n",
    "    val_loss, avl_acc, val_auc = val_epoch(model, val_dataloader, criterion, device)\n",
    "    print(\"epoch - {} val_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, val_loss, avl_acc, val_auc))\n",
    "    \n",
    "    if val_auc > last_auc:\n",
    "        last_auc = val_auc\n",
    "        over_fit = 0\n",
    "    else:\n",
    "        over_fit += 1\n",
    "        \n",
    "    \n",
    "    if over_fit >= 2:\n",
    "        print(\"early stop epoch \", epoch)\n",
    "        break\n",
    "\n",
    "## epoch - 16 val_loss - 0.57 acc - 0.702 auc - 0.759\n",
    "## early stop epoch  16\n",
    "## CPU times: user 16min 22s, sys: 59.1 s, total: 17min 21s\n",
    "## Wall time: 20min 10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:41:08.813873Z",
     "iopub.status.busy": "2021-01-06T21:41:08.812003Z",
     "iopub.status.idle": "2021-01-06T21:41:08.814596Z",
     "shell.execute_reply": "2021-01-06T21:41:08.815096Z"
    },
    "papermill": {
     "duration": 1.827827,
     "end_time": "2021-01-06T21:41:08.815221",
     "exception": false,
     "start_time": "2021-01-06T21:41:06.987394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, samples, test_df, skills, max_seq=100):\n",
    "        super(TestDataset, self).__init__()\n",
    "        ## Append test_df info to group (the original training dataframe)\n",
    "        ## Input group as \"samples\" for TestDataset\n",
    "        self.samples = samples\n",
    "        self.user_ids = [x for x in test_df[\"user_id\"].unique()]\n",
    "        self.test_df = test_df\n",
    "        self.skills = skills\n",
    "        self.n_skill = len(skills)\n",
    "        self.max_seq = max_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.test_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        test_info = self.test_df.iloc[index]\n",
    "\n",
    "        user_id = test_info[\"user_id\"]\n",
    "        target_id = test_info[\"content_id\"]\n",
    "\n",
    "        q = np.zeros(self.max_seq, dtype=int)\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "        \n",
    "        ## Extract user info from samples (the original training dataframe + test_df info)\n",
    "        ## If user does not exist in samples, return q with all zeros\n",
    "        if user_id in self.samples.index:\n",
    "            q_, qa_ = self.samples[user_id]\n",
    "            \n",
    "            seq_len = len(q_)\n",
    "\n",
    "            if seq_len >= self.max_seq:\n",
    "                q = q_[-self.max_seq:]\n",
    "                qa = qa_[-self.max_seq:]\n",
    "            else:\n",
    "                q[-seq_len:] = q_\n",
    "                qa[-seq_len:] = qa_          \n",
    "        \n",
    "        x = np.zeros(self.max_seq-1, dtype=int)\n",
    "        x = q[1:].copy()\n",
    "        x += (qa[1:] == 1) * self.n_skill\n",
    "        \n",
    "        questions = np.append(q[2:], [target_id])\n",
    "        \n",
    "        return x, questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:41:13.549780Z",
     "iopub.status.busy": "2021-01-06T21:41:13.548946Z",
     "iopub.status.idle": "2021-01-06T21:41:13.568883Z",
     "shell.execute_reply": "2021-01-06T21:41:13.567797Z"
    },
    "papermill": {
     "duration": 2.945586,
     "end_time": "2021-01-06T21:41:13.568985",
     "exception": false,
     "start_time": "2021-01-06T21:41:10.623399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_test = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/example_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:41:17.842239Z",
     "iopub.status.busy": "2021-01-06T21:41:17.841313Z",
     "iopub.status.idle": "2021-01-06T21:41:17.882760Z",
     "shell.execute_reply": "2021-01-06T21:41:17.883772Z"
    },
    "papermill": {
     "duration": 2.119516,
     "end_time": "2021-01-06T21:41:17.883933",
     "exception": false,
     "start_time": "2021-01-06T21:41:15.764417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>group_num</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>prior_group_answers_correct</th>\n",
       "      <th>prior_group_responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>275030867</td>\n",
       "      <td>5729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13309898705</td>\n",
       "      <td>554169193</td>\n",
       "      <td>12010</td>\n",
       "      <td>0</td>\n",
       "      <td>4427</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4213672059</td>\n",
       "      <td>1720860329</td>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>62798072960</td>\n",
       "      <td>288641214</td>\n",
       "      <td>13262</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10585422061</td>\n",
       "      <td>1728340777</td>\n",
       "      <td>6119</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>72400.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>18020362258</td>\n",
       "      <td>1364159702</td>\n",
       "      <td>12023</td>\n",
       "      <td>0</td>\n",
       "      <td>4424</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2325432079</td>\n",
       "      <td>1521618396</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>1367</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>39456940781</td>\n",
       "      <td>1317245193</td>\n",
       "      <td>12043</td>\n",
       "      <td>0</td>\n",
       "      <td>5314</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3460555189</td>\n",
       "      <td>1700555100</td>\n",
       "      <td>7910</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2214770464</td>\n",
       "      <td>998511398</td>\n",
       "      <td>7908</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>516803182</td>\n",
       "      <td>1422853669</td>\n",
       "      <td>1143</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2153839851</td>\n",
       "      <td>1096784725</td>\n",
       "      <td>11033</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>34250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2153839851</td>\n",
       "      <td>1096784725</td>\n",
       "      <td>11032</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>34250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2153839851</td>\n",
       "      <td>1096784725</td>\n",
       "      <td>11034</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>34250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2153839851</td>\n",
       "      <td>1096784725</td>\n",
       "      <td>11031</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>34250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1218852591</td>\n",
       "      <td>385471210</td>\n",
       "      <td>9538</td>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>32722340115</td>\n",
       "      <td>1202386221</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2059097926</td>\n",
       "      <td>2018567473</td>\n",
       "      <td>12148</td>\n",
       "      <td>0</td>\n",
       "      <td>589</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>23609</td>\n",
       "      <td>275030867</td>\n",
       "      <td>5502</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 3, 3, 1, 1, 0, 3, 1, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2035159380</td>\n",
       "      <td>1233875513</td>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>1431</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2035159380</td>\n",
       "      <td>1233875513</td>\n",
       "      <td>1511</td>\n",
       "      <td>0</td>\n",
       "      <td>1431</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2035159380</td>\n",
       "      <td>1233875513</td>\n",
       "      <td>1513</td>\n",
       "      <td>0</td>\n",
       "      <td>1431</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1217231</td>\n",
       "      <td>891955351</td>\n",
       "      <td>9145</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>11265012636</td>\n",
       "      <td>1981166446</td>\n",
       "      <td>3299</td>\n",
       "      <td>0</td>\n",
       "      <td>950</td>\n",
       "      <td>36333.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>11265012636</td>\n",
       "      <td>1981166446</td>\n",
       "      <td>3297</td>\n",
       "      <td>0</td>\n",
       "      <td>950</td>\n",
       "      <td>36333.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>11265012636</td>\n",
       "      <td>1981166446</td>\n",
       "      <td>3298</td>\n",
       "      <td>0</td>\n",
       "      <td>950</td>\n",
       "      <td>36333.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4693145319</td>\n",
       "      <td>1637273633</td>\n",
       "      <td>11373</td>\n",
       "      <td>0</td>\n",
       "      <td>3148</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2294633294</td>\n",
       "      <td>2030979309</td>\n",
       "      <td>3348</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>30666.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2294633294</td>\n",
       "      <td>2030979309</td>\n",
       "      <td>3350</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>30666.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2294633294</td>\n",
       "      <td>2030979309</td>\n",
       "      <td>3349</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>30666.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>13679981387</td>\n",
       "      <td>319060572</td>\n",
       "      <td>10951</td>\n",
       "      <td>0</td>\n",
       "      <td>621</td>\n",
       "      <td>30250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>13679981387</td>\n",
       "      <td>319060572</td>\n",
       "      <td>10953</td>\n",
       "      <td>0</td>\n",
       "      <td>621</td>\n",
       "      <td>30250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>13679981387</td>\n",
       "      <td>319060572</td>\n",
       "      <td>10954</td>\n",
       "      <td>0</td>\n",
       "      <td>621</td>\n",
       "      <td>30250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>13679981387</td>\n",
       "      <td>319060572</td>\n",
       "      <td>10952</td>\n",
       "      <td>0</td>\n",
       "      <td>621</td>\n",
       "      <td>30250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>62798100988</td>\n",
       "      <td>288641214</td>\n",
       "      <td>5418</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>251107302</td>\n",
       "      <td>98059812</td>\n",
       "      <td>5892</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1254086842</td>\n",
       "      <td>674533997</td>\n",
       "      <td>5301</td>\n",
       "      <td>0</td>\n",
       "      <td>1044</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>44526338636</td>\n",
       "      <td>555691277</td>\n",
       "      <td>666</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>39456965438</td>\n",
       "      <td>1317245193</td>\n",
       "      <td>12195</td>\n",
       "      <td>0</td>\n",
       "      <td>5315</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>32722359498</td>\n",
       "      <td>1202386221</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>417208826</td>\n",
       "      <td>775113212</td>\n",
       "      <td>10078</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>28250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>417208826</td>\n",
       "      <td>775113212</td>\n",
       "      <td>10080</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>28250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>417208826</td>\n",
       "      <td>775113212</td>\n",
       "      <td>10081</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>28250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>417208826</td>\n",
       "      <td>775113212</td>\n",
       "      <td>10079</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>28250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>209087981</td>\n",
       "      <td>1219481379</td>\n",
       "      <td>3784</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>42512</td>\n",
       "      <td>275030867</td>\n",
       "      <td>6133</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 2, 2, 2, 1, 0, 1, 2, 1, 1, 3, 2, 0, 0, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2325462978</td>\n",
       "      <td>1521618396</td>\n",
       "      <td>786</td>\n",
       "      <td>0</td>\n",
       "      <td>1368</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>76816459637</td>\n",
       "      <td>1148874033</td>\n",
       "      <td>5038</td>\n",
       "      <td>0</td>\n",
       "      <td>6958</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>13309942648</td>\n",
       "      <td>554169193</td>\n",
       "      <td>1260</td>\n",
       "      <td>0</td>\n",
       "      <td>4428</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>18643018681</td>\n",
       "      <td>1281335472</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>771</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  group_num    timestamp     user_id  content_id  content_type_id  \\\n",
       "0        0          0            0   275030867        5729                0   \n",
       "1        1          0  13309898705   554169193       12010                0   \n",
       "2        2          0   4213672059  1720860329         457                0   \n",
       "3        3          0  62798072960   288641214       13262                0   \n",
       "4        4          0  10585422061  1728340777        6119                0   \n",
       "5        5          0  18020362258  1364159702       12023                0   \n",
       "6        6          0   2325432079  1521618396         574                0   \n",
       "7        7          0  39456940781  1317245193       12043                0   \n",
       "8        8          0   3460555189  1700555100        7910                0   \n",
       "9        9          0   2214770464   998511398        7908                0   \n",
       "10      10          0    516803182  1422853669        1143                0   \n",
       "11      11          0   2153839851  1096784725       11033                0   \n",
       "12      12          0   2153839851  1096784725       11032                0   \n",
       "13      13          0   2153839851  1096784725       11034                0   \n",
       "14      14          0   2153839851  1096784725       11031                0   \n",
       "15      15          0   1218852591   385471210        9538                0   \n",
       "16      16          0  32722340115  1202386221        1002                0   \n",
       "17      17          0   2059097926  2018567473       12148                0   \n",
       "18      18          1        23609   275030867        5502                0   \n",
       "19      19          1   2035159380  1233875513        1512                0   \n",
       "20      20          1   2035159380  1233875513        1511                0   \n",
       "21      21          1   2035159380  1233875513        1513                0   \n",
       "22      22          1      1217231   891955351        9145                0   \n",
       "23      23          1  11265012636  1981166446        3299                0   \n",
       "24      24          1  11265012636  1981166446        3297                0   \n",
       "25      25          1  11265012636  1981166446        3298                0   \n",
       "26      26          1   4693145319  1637273633       11373                0   \n",
       "27      27          1   2294633294  2030979309        3348                0   \n",
       "28      28          1   2294633294  2030979309        3350                0   \n",
       "29      29          1   2294633294  2030979309        3349                0   \n",
       "30      30          1  13679981387   319060572       10951                0   \n",
       "31      31          1  13679981387   319060572       10953                0   \n",
       "32      32          1  13679981387   319060572       10954                0   \n",
       "33      33          1  13679981387   319060572       10952                0   \n",
       "34      34          1  62798100988   288641214        5418                0   \n",
       "35      35          1    251107302    98059812        5892                0   \n",
       "36      37          1   1254086842   674533997        5301                0   \n",
       "37      38          1  44526338636   555691277         666                0   \n",
       "38      39          1  39456965438  1317245193       12195                0   \n",
       "39      40          1  32722359498  1202386221         582                0   \n",
       "40      41          1    417208826   775113212       10078                0   \n",
       "41      42          1    417208826   775113212       10080                0   \n",
       "42      43          1    417208826   775113212       10081                0   \n",
       "43      44          1    417208826   775113212       10079                0   \n",
       "44      45          1    209087981  1219481379        3784                0   \n",
       "45      46          2        42512   275030867        6133                0   \n",
       "46      47          2   2325462978  1521618396         786                0   \n",
       "47      48          2  76816459637  1148874033        5038                0   \n",
       "48      49          2  13309942648   554169193        1260                0   \n",
       "49      50          2  18643018681  1281335472         175                0   \n",
       "\n",
       "    task_container_id  prior_question_elapsed_time  \\\n",
       "0                   0                          NaN   \n",
       "1                4427                      19000.0   \n",
       "2                 240                      17000.0   \n",
       "3                 266                      23000.0   \n",
       "4                 162                      72400.0   \n",
       "5                4424                      18000.0   \n",
       "6                1367                      18000.0   \n",
       "7                5314                      17000.0   \n",
       "8                 532                      21000.0   \n",
       "9                 393                      21000.0   \n",
       "10                 85                      15000.0   \n",
       "11                315                      34250.0   \n",
       "12                315                      34250.0   \n",
       "13                315                      34250.0   \n",
       "14                315                      34250.0   \n",
       "15                378                      11000.0   \n",
       "16                136                      16000.0   \n",
       "17                589                      17000.0   \n",
       "18                  1                      34000.0   \n",
       "19               1431                      25000.0   \n",
       "20               1431                      25000.0   \n",
       "21               1431                      25000.0   \n",
       "22                 20                      23000.0   \n",
       "23                950                      36333.0   \n",
       "24                950                      36333.0   \n",
       "25                950                      36333.0   \n",
       "26               3148                      41000.0   \n",
       "27                170                      30666.0   \n",
       "28                170                      30666.0   \n",
       "29                170                      30666.0   \n",
       "30                621                      30250.0   \n",
       "31                621                      30250.0   \n",
       "32                621                      30250.0   \n",
       "33                621                      30250.0   \n",
       "34                267                      24000.0   \n",
       "35                  9                      34000.0   \n",
       "36               1044                      29000.0   \n",
       "37                 52                      25000.0   \n",
       "38               5315                      18000.0   \n",
       "39                137                      17000.0   \n",
       "40                128                      28250.0   \n",
       "41                128                      28250.0   \n",
       "42                128                      28250.0   \n",
       "43                128                      28250.0   \n",
       "44                 40                      22000.0   \n",
       "45                  2                      17000.0   \n",
       "46               1368                      19000.0   \n",
       "47               6958                      12000.0   \n",
       "48               4428                      18000.0   \n",
       "49                771                      24000.0   \n",
       "\n",
       "   prior_question_had_explanation  \\\n",
       "0                             NaN   \n",
       "1                            True   \n",
       "2                            True   \n",
       "3                            True   \n",
       "4                            True   \n",
       "5                            True   \n",
       "6                            True   \n",
       "7                            True   \n",
       "8                            True   \n",
       "9                            True   \n",
       "10                           True   \n",
       "11                           True   \n",
       "12                           True   \n",
       "13                           True   \n",
       "14                           True   \n",
       "15                           True   \n",
       "16                           True   \n",
       "17                           True   \n",
       "18                          False   \n",
       "19                           True   \n",
       "20                           True   \n",
       "21                           True   \n",
       "22                           True   \n",
       "23                           True   \n",
       "24                           True   \n",
       "25                           True   \n",
       "26                           True   \n",
       "27                           True   \n",
       "28                           True   \n",
       "29                           True   \n",
       "30                           True   \n",
       "31                           True   \n",
       "32                           True   \n",
       "33                           True   \n",
       "34                           True   \n",
       "35                           True   \n",
       "36                           True   \n",
       "37                           True   \n",
       "38                           True   \n",
       "39                           True   \n",
       "40                           True   \n",
       "41                           True   \n",
       "42                           True   \n",
       "43                           True   \n",
       "44                           True   \n",
       "45                          False   \n",
       "46                           True   \n",
       "47                           True   \n",
       "48                           True   \n",
       "49                           True   \n",
       "\n",
       "                          prior_group_answers_correct  \\\n",
       "0                                                  []   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18  [0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, ...   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "30                                                NaN   \n",
       "31                                                NaN   \n",
       "32                                                NaN   \n",
       "33                                                NaN   \n",
       "34                                                NaN   \n",
       "35                                                NaN   \n",
       "36                                                NaN   \n",
       "37                                                NaN   \n",
       "38                                                NaN   \n",
       "39                                                NaN   \n",
       "40                                                NaN   \n",
       "41                                                NaN   \n",
       "42                                                NaN   \n",
       "43                                                NaN   \n",
       "44                                                NaN   \n",
       "45  [1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, ...   \n",
       "46                                                NaN   \n",
       "47                                                NaN   \n",
       "48                                                NaN   \n",
       "49                                                NaN   \n",
       "\n",
       "                                prior_group_responses  \n",
       "0                                                  []  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18  [0, 0, 1, 1, 0, 1, 3, 3, 1, 1, 0, 3, 1, 2, 2, ...  \n",
       "19                                                NaN  \n",
       "20                                                NaN  \n",
       "21                                                NaN  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  \n",
       "25                                                NaN  \n",
       "26                                                NaN  \n",
       "27                                                NaN  \n",
       "28                                                NaN  \n",
       "29                                                NaN  \n",
       "30                                                NaN  \n",
       "31                                                NaN  \n",
       "32                                                NaN  \n",
       "33                                                NaN  \n",
       "34                                                NaN  \n",
       "35                                                NaN  \n",
       "36                                                NaN  \n",
       "37                                                NaN  \n",
       "38                                                NaN  \n",
       "39                                                NaN  \n",
       "40                                                NaN  \n",
       "41                                                NaN  \n",
       "42                                                NaN  \n",
       "43                                                NaN  \n",
       "44                                                NaN  \n",
       "45  [1, 2, 2, 2, 1, 0, 1, 2, 1, 1, 3, 2, 0, 0, 3, ...  \n",
       "46                                                NaN  \n",
       "47                                                NaN  \n",
       "48                                                NaN  \n",
       "49                                                NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_test.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:41:21.573005Z",
     "iopub.status.busy": "2021-01-06T21:41:21.570702Z",
     "iopub.status.idle": "2021-01-06T21:41:21.576596Z",
     "shell.execute_reply": "2021-01-06T21:41:21.575817Z"
    },
    "papermill": {
     "duration": 1.857508,
     "end_time": "2021-01-06T21:41:21.576734",
     "exception": false,
     "start_time": "2021-01-06T21:41:19.719226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(eval(example_test['prior_group_answers_correct'].iloc[18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:41:25.240106Z",
     "iopub.status.busy": "2021-01-06T21:41:25.239006Z",
     "iopub.status.idle": "2021-01-06T21:41:25.248913Z",
     "shell.execute_reply": "2021-01-06T21:41:25.249667Z"
    },
    "papermill": {
     "duration": 1.844025,
     "end_time": "2021-01-06T21:41:25.249857",
     "exception": false,
     "start_time": "2021-01-06T21:41:23.405832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(example_test['prior_group_answers_correct'].iloc[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:41:29.082437Z",
     "iopub.status.busy": "2021-01-06T21:41:29.081660Z",
     "iopub.status.idle": "2021-01-06T21:41:29.107740Z",
     "shell.execute_reply": "2021-01-06T21:41:29.106672Z"
    },
    "papermill": {
     "duration": 1.845876,
     "end_time": "2021-01-06T21:41:29.107843",
     "exception": false,
     "start_time": "2021-01-06T21:41:27.261967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "\n",
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-06T21:41:32.765568Z",
     "iopub.status.busy": "2021-01-06T21:41:32.763895Z",
     "iopub.status.idle": "2021-01-06T21:41:33.429249Z",
     "shell.execute_reply": "2021-01-06T21:41:33.429950Z"
    },
    "papermill": {
     "duration": 2.483789,
     "end_time": "2021-01-06T21:41:33.430153",
     "exception": false,
     "start_time": "2021-01-06T21:41:30.946364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 34.27it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 76.53it/s]\n",
      "2it [00:00, 12.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 67.15it/s]\n",
      "\n",
      "100%|██████████| 1/1 [00:00<00:00, 71.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.1\n",
      "43.2\n",
      "43.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  6.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "model.eval()\n",
    "\n",
    "prev_test_df = None\n",
    "MAX_SEQ = 100\n",
    "\n",
    "for (test_df, sample_prediction_df) in tqdm(iter_test):\n",
    "    if (prev_test_df is not None) & (psutil.virtual_memory().percent<90):\n",
    "        print(psutil.virtual_memory().percent)\n",
    "        ## prior_group_responses (string) provides all of the user_answer entries for \n",
    "        ## previous group in a string representation of a list in the first row of the group. \n",
    "        ## All other rows in each group are null. If you are using Python, you will likely want to call eval on the non-null rows. Some rows may be null, or empty lists.\n",
    "        \n",
    "        ## prior_group_answers_correct (string) provides all the answered_correctly field for previous group, \n",
    "        ## with the same format and caveats as prior_group_responses. Some rows may be null, or empty lists.\n",
    "        \n",
    "        ## For test_df, the answers and answer correctness of the previous test_df (group) is always in the first row\n",
    "        ## prior_group_answers_correct and prior_group_responses always have the same length as the previous test_df \n",
    "        prev_test_df['answered_correctly'] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "        prev_test_df = prev_test_df[prev_test_df.content_type_id == False]\n",
    "        prev_group = prev_test_df[['user_id', 'content_id', 'answered_correctly']].groupby('user_id').apply(lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values))\n",
    "        \n",
    "        for prev_user_id in prev_group.index:\n",
    "            ## for each user in previous group get content_id (questions) and answered_correctly (correctness of answer to question)\n",
    "            prev_group_content = prev_group[prev_user_id][0]\n",
    "            prev_group_ac = prev_group[prev_user_id][1]\n",
    "            \n",
    "            ## If user in previous group also in *training group*, append questions and answer accuracy to user entry in training group\n",
    "            ## Otherwise just add user to training group\n",
    "\n",
    "            if prev_user_id in group.index:\n",
    "                group[prev_user_id] = (np.append(group[prev_user_id][0],prev_group_content), \n",
    "                                       np.append(group[prev_user_id][1],prev_group_ac))\n",
    "             \n",
    "            else:\n",
    "                group[prev_user_id] = (prev_group_content,prev_group_ac)\n",
    "            \n",
    "            ## Trim sequence in training group to match max_seq (maximum sequence length model will handle)\n",
    "            if len(group[prev_user_id][0])>MAX_SEQ:\n",
    "                new_group_content = group[prev_user_id][0][-MAX_SEQ:]\n",
    "                new_group_ac = group[prev_user_id][1][-MAX_SEQ:]\n",
    "                group[prev_user_id] = (new_group_content,new_group_ac)\n",
    "\n",
    "    prev_test_df = test_df.copy()\n",
    "    \n",
    "    test_df = test_df[test_df.content_type_id == False]\n",
    "    \n",
    "    test_dataset = TestDataset(group, test_df, skills)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=51200, shuffle=False)\n",
    "    \n",
    "    outs = []\n",
    "\n",
    "    for item in tqdm(test_dataloader):\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, att_weight = model(x, target_id)\n",
    "        \n",
    "        \n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[:, -1]\n",
    "\n",
    "        # pred = (output >= 0.5).long()\n",
    "        # loss = criterion(output, label)\n",
    "\n",
    "        # val_loss.append(loss.item())\n",
    "        # num_corrects += (pred == label).sum().item()\n",
    "        # num_total += len(label)\n",
    "\n",
    "        # labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "        \n",
    "    test_df['answered_correctly'] =  outs\n",
    "    \n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1187.136535,
   "end_time": "2021-01-06T21:41:36.951071",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-06T21:21:49.814536",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
